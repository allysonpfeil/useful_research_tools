# useful_research_tools/propensity_score_matching
### by: [Allyson Pfeil](https://github.com/allysonpfeil)

Propensity Scores are often calculated in scientific research in an attempt to verify observable changes are due to the treatment group and not demographic differences. Personally, I believe that this concern is better addressed with a regression analysis that assesses whether or not variables (features) influence the outcome. I have previously written several regression analyses on GitHub and will likely write more, but the basics of propensity scores are still important. If for nothing else, propensity scoring and statistical cohort integrity techniques can be a fun conversation starter while also demonstrating value to whoever you are trying to impress with robust statistical knowledge. 

## When to use propensity scores:
Propensity scores are best used in instances that, if a cohort difference is observed, you want to ensure that the study was homogenous enough to demonstrate the observed outcome was truly due to the experimental conditions - not biases. As an example, if you want to study if drug AlphaBravo is truly effective, you would want to create a control and experimental group. The control group would receive a placebo, and the experimental group would receive AlphaBravo. If AlphaBravo affects patients of various backgrounds and stages of life, your cohorts might have a diverse mix of demographics and health conditions. With propensity scoring, you seek to match the experimental patients to control patients based on these differences (demographic or otherwise) to most accurately make comparisons about AlphaBravo's effect. 

## What is a propensity score:
A propensity score is a mathematical probability that an instance is observably similar to another instance with a different outcome. It helps to ensure observable variables in the control group have significant overlap with the obervable variables in the experimental group, effectively minimizing confounding variables and selection bias. Although not a complete solution, implementing some statistical control over the cohorts to ensure as much homogeneity as possible is a gold standard in research. 

## Code overview:
### [calc_prop_scores](calc_prop_scores.py)
This code is straightforward. The hardest part will likely be assigning what will and will not be accounted for in the propensity score. Typically, variables such as 'age', 'sex', 'weight', 'height', 'race', 'disease stage' would be good starting points to identify your independent variables. Consult with your local statistician or ChatGPT to further assess variable selection. 
Successful execution of this code will print the propensity scores that you would then want to add to your excel sheet. Unfortunately, I am not allowed to have permissions to write to excel from Python, so I wrote this in a more "manual" way. The most efficient way would be to write the propensity scores to Excel in a designated column. 

### [match_prop_scores](match_prop_scores.py)
This code is a little bit more complex, but hardly. Assuming that you have now added the propensity scores to your excel file, the code defines the control and experimental groups based on the one-hot encoding I am also assuming you did. Then, it defines a K-nearest model to find the closest score from experimental to control (once again, assunming the experimental cohort is the limiting variable). If not, the code still works the same, but the explanation might be a little different. This code has logic to not repeat assigning control instances to experimental instances - this can be removed, but I have no idea why anyone would. Lastly, it prints a short statement on each instance and which instance it was matched to. There is no interpretation needed - the model directly says who is matched. 
